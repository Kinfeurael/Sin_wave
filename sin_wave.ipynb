{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d98cc2-b048-4c47-993a-be0738b20a22",
   "metadata": {},
   "source": [
    "# Sin wave RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae88e338-1fc8-4c86-8787-2c805ce48022",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da87655-619b-46d7-9146-6f877ea9f49c",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8eb699-b874-47e6-8a4f-c2ba5d273b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"Sin Wave Data Generator.csv\")\n",
    "wave_data = df['Wave'].values\n",
    "\n",
    "# 2. Prepare data using a sliding window\n",
    "def create_dataset(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 50\n",
    "X, y = create_dataset(wave_data, window_size)\n",
    "\n",
    "# 3. Normalize data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Function to build and train model\n",
    "def build_and_train_model(activation, epochs=100):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(X_train.shape[1],), activation=activation),\n",
    "        Dense(64, activation=activation),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                        epochs=epochs, verbose=0)\n",
    "    return history.history['loss'], history.history['val_loss']\n",
    "\n",
    "# 6. Compare Sigmoid, Tanh, ReLU\n",
    "activations = ['sigmoid', 'tanh', 'relu']\n",
    "loss_histories = {}\n",
    "\n",
    "for act in activations:\n",
    "    print(f\"Training with activation: {act}\")\n",
    "    train_loss, val_loss = build_and_train_model(act)\n",
    "    loss_histories[act] = {'train': train_loss, 'val': val_loss}\n",
    "\n",
    "# 7. Plot losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "for act in activations:\n",
    "    plt.plot(loss_histories[act]['val'], label=f'{act} (val loss)')\n",
    "plt.title('Validation Loss Comparison: Sigmoid vs Tanh vs ReLU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d160b8-5723-4c11-8f05-060bd8dd2b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU, PReLU\n",
    "\n",
    "# Function to create and train model with flexible activation\n",
    "def build_model_with_custom_activation(activation_layer, depth=2, epochs=100):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(X_train.shape[1],)))\n",
    "    model.add(activation_layer())\n",
    "\n",
    "    for _ in range(depth - 1):\n",
    "        model.add(Dense(64))\n",
    "        model.add(activation_layer())\n",
    "    \n",
    "    model.add(Dense(1))  # Output layer\n",
    "    model.compile(optimizer=Adam(0.001), loss='mse')\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                        epochs=epochs, verbose=0)\n",
    "    return history.history['val_loss']\n",
    "\n",
    "# Compare ReLU variants\n",
    "relu_variants = {\n",
    "    'ReLU': tf.keras.layers.ReLU,\n",
    "    'Leaky ReLU': lambda: LeakyReLU(alpha=0.01),\n",
    "    'Parametric ReLU': lambda: PReLU()\n",
    "}\n",
    "\n",
    "variant_losses = {}\n",
    "for name, act_fn in relu_variants.items():\n",
    "    print(f\"Training model with {name}\")\n",
    "    loss = build_model_with_custom_activation(act_fn, depth=2)\n",
    "    variant_losses[name] = loss\n",
    "\n",
    "# Plot ReLU variant performance\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, loss in variant_losses.items():\n",
    "    plt.plot(loss, label=f'{name}')\n",
    "plt.title('Validation Loss Comparison: ReLU Variants')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3478d-4790-4e2e-a3da-a8f41abe8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now explore depth (1 to 5 layers) with standard ReLU\n",
    "depth_losses = {}\n",
    "for d in range(1, 6):\n",
    "    print(f\"Training with depth {d}\")\n",
    "    loss = build_model_with_custom_activation(tf.keras.layers.ReLU, depth=d)\n",
    "    depth_losses[d] = loss\n",
    "\n",
    "# Plot performance vs depth\n",
    "final_losses = [loss[-1] for loss in depth_losses.values()]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(depth_losses.keys()), final_losses, marker='o')\n",
    "plt.title('Effect of Network Depth on Test Loss')\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Final Validation MSE')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
